## 工作总结
- **2018-03-19**
- **于增源**
- **项目地址[github](https://github.com/ZengyuanYu/Machine-Learning/tree/master/XGBoost)**
## 使用XGBoost预测台风发生频次

### 原始数据的处理
	1. 原始数据是以*.mat*方式存放的，为了读取里面的信息，我使用`import scipy.io`这个包来直接读取MATLAB文件，读取到的MATLAB文件的格式如下：
> {'__header__': b'MATLAB 5.0 MAT-file, Platform: PCWIN64, Created on: Sat Feb 24 16:08:02 2018', '__version__': '1.0', '__globals__': [], 'hgt_yy': array([[5747.49072266, 5772.66162109, 5748.60563151, ..., 5213.26611328,
        5255.63557943, 5244.59488932],
       [5751.62369792, 5777.90690104, 5755.05371094, ..., 5325.82096354,
        5375.56738281, 5367.78629557],
       [5747.20491536, 5783.3421224 , 5745.72884115, ..., 5261.3141276 ,
        5297.08300781, 5295.47509766],
       ...,
       [5769.34033203, 5796.07763672, 5770.35742188, ..., 5195.953125  ,
        5233.53304036, 5231.8671875 ],
       [5777.25113932, 5812.8523763 , 5774.36149089, ..., 5211.1336263 ,
        5259.86360677, 5262.28645833],
       [5833.63590495, 5850.77229818, 5834.70556641, ..., 5355.20572917,
        5373.07747396, 5374.23144531]])}

可见数据是以字典的形式存储，所以我读出数据文件将其存放到`name_list`这个变量列表之中，以此类推将三个文件的全部数据都按照此方法提取出来；
	2.已只所有的数据的权重一样全部作为影响因子来决定台风频次，所以将三者合并并保存到一个`csv`文件之中，这里我使用`import csv`通过逐行写入的方式来将其写入。
	3.训练集是一个含有头标签和index的csv文件，对于Labels给出的是excel文件的格式，为了方便处理，也将其读取成为`csv`文件，这里我使用`import xlrd`来进行excel的数据处理。
**经过处理之后得到了一些不同处理结果的训练集和测试集，我最先使用的是X_noyear.csv和Y_noyear.csv做为训练样本进行操作**

### 训练
#### 一个错误的尝试
参考泰坦尼克号的遇难名单预测来移植到此训练集，利用`train_test_split`和`min_max_scaler`来进行数据集的划分和最大最小值标准化，因错误的使用分类器而不是回归器所以方法是错误的。
#### 现阶段进度
- 存在的问题
	1.首先参考二噁英的代码中XGBoost分类器的构建，直接运用到本数据集上，但在训练的过程中`让r2_score`的值一直在0.35左右但是测试集却在0.999左右，经过对代码的分析，是因为原始代码并没有对数据集进行划分，直接拿数据集进行训练，再拿此数据集中的一部分进行预测，这不符合机器学习划分样本的规则，即使效果很好，但是没有泛化性，得出来的分数是自欺欺人。
	2.测试结果0.999的原因是在XGboost中的测试部分，竟然是使用测试的样本先进行训练，再拿此样本进行测试，显然这个分数是没有丝毫价值的。

- 我的改进
	1.首先，在原始数据集上，我通过原始数据处理中的方法将数据集进行按照一定比列（0.25）进行分割，得到四个csv文件：
		- X_50.csv
		- X_16.csv
		- Y_50.csv
		- Y_16.csv
与此同时，修改测试代码，删除里面的`XGBTrain(test_x, test_y)`此行；
	2.然后训练的大致过程为`X_50.csv`放入训练函数中，进行训练得到一个含有参数的`model`，然后在测试中放入`X_16.csv`，利用训练好的模型去测试来得到分数。

- 调参
	1.这样做我个人觉得整体思路没有问题，得出来的分数是可信的，但是训练出来的效果并不好，刚开始只有0.27（查文档可知最大值为1，但会出现负值），而测试分数略低于训练分数。接下来就是调参，函数中给出了三个参数：学习率，树数，树深。下面是调参时不同组合的成功率：
**不同参数下XGBoost预测台风的准确度**

No.|learning_rate|n_estimators|max_depth|train_score|test_score
-|:-:|:-:|:-:|:-:|-:
1|0.2|500|16|0.387|0.036
2|0.2|500|8|0.387|0.036
3|0.2|500|3|0.151|0.192
4|0.2|400|16|0.387|0.036
5|0.2|400|8|0.387|0.036
6|0.2|400|3|0.151|0.192
7|0.1|500|16|0.440|0.301
8|0.1|500|8|0.440|0.301
9|0.1|500|3|0.470|0.426
10|0.1|400|16|0.440|0.301
11|0.1|400|8|0.440|0.301
12|0.1|400|3|0.470|0.426

由上表可知，现阶段最大的成功分数是0.470，相应的测试分数为0.426。通过`plt`画图得到的分数来看距离差不多，还不是十分准确的原因在于数据，或者需要采用其他的机器学习方法。因为纵然给了66*498个数据，但是只有66个样本，每一个样本却由498个因子去影响，这很容易造成拟合问题，数据量太少而特征太多，导致效果并没有像kaggle里面对三维数据处理那么好的表现力。
