## SVM理解

支持向量机的优点为：

- 在高维空间依然有效
- 在维数大于样本数的情况下让然有效
- 在决策函数中使用一个训练点的子集（成为支持向量），所以它也是有效的
- 通用：可以依赖决策功能指定不同的内核函数，提供了通用内核，也可以指定自定义内核

支持向量机的缺点：

- 如果特征数量远大于样本数量，那么内核函数的选择和正则化非常重要且难以选择
- 支持向量机不提供概率估计，这么都需要使用5折交叉验证来获取

### 一、了解SVM

**支持向量机（SVM）**是一组用于分类，回归和异常值检测的有监督学习方法。通俗来讲，它是一种二分类模型，在基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，最终可转化成为一个凸二次规划问题。

#### 1.1 分类标准的起源：Logistic回归

线性分类器了解一下。

给定一些数据集，它们分别属于两个不同的类，现在要找到一个线性分类器把这些数据分成两类。如果用x表示数据点，用y表示类别（y可以取1或者-1，代表两个不同的类），一个线性分类器的学习目标便是要在n维的数据空间中找到一个超平面（hyper plane），这个超平面的方程可以表示为：

​								$${w^T}x + b = 0$$

为什么类别取值为1或-1呢？事实上这个分类标准起源于logistic回归。

Logistic回归的目的是从特征学习出一个0/1分类的模型，

